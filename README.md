# templrjs-llm-chat-webui
A simple LLM chat webgui for models hosted in local ollama and cloud cloudflare using generic chat completions api  
